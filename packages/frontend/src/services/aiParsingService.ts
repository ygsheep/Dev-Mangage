// AIè§£ææœåŠ¡ - ä½¿ç”¨å°æ¨¡å‹è¿›è¡Œæ™ºèƒ½æ–‡æ¡£è§£æ
import { API, HTTPMethod, APIStatus, DatabaseTable } from '@shared/types'

export interface AIParsingConfig {
  provider: 'ollama' | 'deepseek' | 'openai' | 'mock'
  model: string
  baseUrl?: string
  apiKey?: string
}

// æ¨¡å‹Tokené™åˆ¶é…ç½®
export interface ModelLimits {
  maxTokens: number      // æ¨¡å‹æœ€å¤§tokenæ•°
  reserveTokens: number  // ä¸ºå“åº”é¢„ç•™çš„tokenæ•°
  maxInputTokens: number // å®é™…å¯ç”¨äºè¾“å…¥çš„tokenæ•°
}

// AIæ¨¡å‹é™åˆ¶é…ç½®
export const AI_MODEL_LIMITS: Record<string, ModelLimits> = {
  'ollama': { 
    maxTokens: 4096, 
    reserveTokens: 1024, 
    maxInputTokens: 3072 
  },
  'deepseek': { 
    maxTokens: 16384, 
    reserveTokens: 2048, 
    maxInputTokens: 14336 
  },
  'openai': { 
    maxTokens: 16384, 
    reserveTokens: 2048, 
    maxInputTokens: 14336 
  },
  'mock': { 
    maxTokens: 8192, 
    reserveTokens: 1024, 
    maxInputTokens: 7168 
  }
}

// æ–‡æ¡£åˆ†å—ç»“æœæ¥å£
export interface DocumentChunk {
  content: string
  index: number
  type: 'header' | 'api' | 'content'
  title?: string
  estimatedTokens: number
}

// åˆ†å—å¤„ç†ç»“æœæ¥å£
export interface ChunkedParseResult {
  totalChunks: number
  processedChunks: number
  failedChunks: number
  results: ParsedAPIDocument[]
  errors: string[]
}

export interface ParsedAPIDocument {
  apis: API[]
  success: boolean
  errors: string[]
  confidence: number
}

export interface ParsedDatabaseDocument {
  tables: ParsedDatabaseTable[]
  relationships: DatabaseRelationship[]
  indexes: DatabaseIndex[]
  success: boolean
  errors: string[]
  confidence: number
}

export interface ParsedDatabaseTable {
  id: string
  name: string
  displayName: string
  comment?: string
  engine?: string
  charset?: string
  fields: DatabaseField[]
  constraints: DatabaseConstraint[]
  indexes: TableIndex[]
  source?: string
  sqlDefinition?: string
}

export interface DatabaseField {
  name: string
  type: string
  length?: number | null
  nullable: boolean
  primaryKey: boolean
  autoIncrement: boolean
  unique?: boolean
  defaultValue?: any
  comment?: string
}

export interface DatabaseConstraint {
  type: string
  column?: string
  referencedTable?: string
  referencedColumn?: string
  definition?: string
}

export interface TableIndex {
  name: string
  columns: string[]
  type: string
  unique?: boolean
}

export interface DatabaseIndex {
  name: string
  table: string
  columns: string[]
  unique: boolean
  type?: string
}

export interface DatabaseRelationship {
  type: string
  fromTable?: string
  fromColumn: string
  toTable: string
  toColumn: string
}

class AIParsingService {
  private config: AIParsingConfig

  constructor(config: AIParsingConfig) {
    this.config = config
  }

  /**
   * ç®€å•Tokenä¼°ç®— (ä¸­æ–‡å­—ç¬¦æŒ‰2ä¸ªtokenè®¡ç®—ï¼Œè‹±æ–‡æŒ‰0.75ä¸ªtokenè®¡ç®—)
   */
  private estimateTokenCount(text: string): number {
    const chineseChars = (text.match(/[\u4e00-\u9fff]/g) || []).length
    const otherChars = text.length - chineseChars
    return Math.ceil(chineseChars * 2 + otherChars * 0.75)
  }

  /**
   * è·å–å½“å‰æ¨¡å‹çš„Tokené™åˆ¶
   */
  private getModelLimits(): ModelLimits {
    const limits = AI_MODEL_LIMITS[this.config.provider]
    if (!limits) {
      console.warn(`æœªæ‰¾åˆ°${this.config.provider}çš„Tokené™åˆ¶é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®`)
      return AI_MODEL_LIMITS.ollama
    }
    return limits
  }

  /**
   * æ™ºèƒ½æ–‡æ¡£åˆ†å—ç­–ç•¥
   */
  private chunkDocument(content: string): DocumentChunk[] {
    const limits = this.getModelLimits()
    const promptTokens = this.estimateTokenCount(this.getAPIParsingPrompt())
    const availableTokens = limits.maxInputTokens - promptTokens
    
    console.log('åˆ†å—åˆ†æ:', {
      provider: this.config.provider,
      maxInputTokens: limits.maxInputTokens,
      promptTokens,
      availableTokens,
      contentLength: content.length,
      estimatedContentTokens: this.estimateTokenCount(content)
    })

    // å¦‚æœå†…å®¹é•¿åº¦åœ¨é™åˆ¶å†…ï¼Œç›´æ¥è¿”å›å•ä¸ªå—
    const contentTokens = this.estimateTokenCount(content)
    if (contentTokens <= availableTokens) {
      return [{
        content,
        index: 0,
        type: 'content',
        title: 'å®Œæ•´æ–‡æ¡£',
        estimatedTokens: contentTokens
      }]
    }

    // éœ€è¦åˆ†å—å¤„ç†
    const chunks: DocumentChunk[] = []
    const lines = content.split('\n')
    let currentChunk = ''
    let currentTokens = 0
    let chunkIndex = 0

    // ç­–ç•¥1: æŒ‰ç« èŠ‚åˆ†å— (ä¼˜å…ˆçº§æœ€é«˜)
    const sections = this.splitByHeaders(content)
    if (sections.length > 1) {
      return this.chunkBySections(sections, availableTokens)
    }

    // ç­–ç•¥2: æŒ‰APIæ¥å£åˆ†å—
    const apiBlocks = this.extractAPIBlocks(content)
    if (apiBlocks.length > 1) {
      return this.chunkByAPIs(apiBlocks, availableTokens)
    }

    // ç­–ç•¥3: æŒ‰æ®µè½åˆ†å— (ä¿ç•™é‡å )
    return this.chunkByParagraphs(content, availableTokens)
  }

  /**
   * æŒ‰æ ‡é¢˜ç« èŠ‚åˆ†å—
   */
  private splitByHeaders(content: string): Array<{title: string, content: string}> {
    const sections: Array<{title: string, content: string}> = []
    const lines = content.split('\n')
    let currentSection = { title: '', content: '' }

    for (const line of lines) {
      const headerMatch = line.match(/^#+\s+(.+)$/)
      if (headerMatch) {
        if (currentSection.content.trim()) {
          sections.push(currentSection)
        }
        currentSection = {
          title: headerMatch[1],
          content: line + '\n'
        }
      } else {
        currentSection.content += line + '\n'
      }
    }

    if (currentSection.content.trim()) {
      sections.push(currentSection)
    }

    return sections
  }

  /**
   * æŒ‰ç« èŠ‚è¿›è¡Œåˆ†å—
   */
  private chunkBySections(sections: Array<{title: string, content: string}>, availableTokens: number): DocumentChunk[] {
    const chunks: DocumentChunk[] = []
    let currentChunk = ''
    let currentTokens = 0
    let chunkIndex = 0

    for (const section of sections) {
      const sectionTokens = this.estimateTokens(section.content)
      
      // å¦‚æœå½“å‰å—åŠ ä¸Šè¿™ä¸ªç« èŠ‚ä¼šè¶…å‡ºé™åˆ¶ï¼Œå…ˆä¿å­˜å½“å‰å—
      if (currentTokens + sectionTokens > availableTokens && currentChunk) {
        chunks.push({
          content: currentChunk.trim(),
          index: chunkIndex++,
          type: 'header',
          title: `åˆ†å— ${chunkIndex}`,
          estimatedTokens: currentTokens
        })
        currentChunk = ''
        currentTokens = 0
      }

      // å¦‚æœå•ä¸ªç« èŠ‚å°±è¶…å‡ºé™åˆ¶ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†å‰²
      if (sectionTokens > availableTokens) {
        const subChunks = this.chunkByParagraphs(section.content, availableTokens)
        chunks.push(...subChunks.map(chunk => ({
          ...chunk,
          index: chunkIndex++,
          title: section.title
        })))
      } else {
        currentChunk += section.content + '\n'
        currentTokens += sectionTokens
      }
    }

    // ä¿å­˜æœ€åä¸€ä¸ªå—
    if (currentChunk.trim()) {
      chunks.push({
        content: currentChunk.trim(),
        index: chunkIndex,
        type: 'header',
        title: `åˆ†å— ${chunkIndex + 1}`,
        estimatedTokens: currentTokens
      })
    }

    return chunks
  }

  /**
   * æå–APIæ¥å£å—
   */
  private extractAPIBlocks(content: string): Array<{title: string, content: string}> {
    const apiBlocks: Array<{title: string, content: string}> = []
    const lines = content.split('\n')
    let currentBlock = { title: '', content: '' }
    let inAPIBlock = false

    for (let i = 0; i < lines.length; i++) {
      const line = lines[i]
      
      // æ£€æµ‹APIæ¥å£å®šä¹‰
      const apiMatch = line.match(/^#{1,4}\s*(.+?)\s*-\s*(GET|POST|PUT|DELETE|PATCH)\s+(.+)$/) ||
                      line.match(/^(GET|POST|PUT|DELETE|PATCH)\s+(.+)$/)
      
      if (apiMatch) {
        // ä¿å­˜ä¸Šä¸€ä¸ªAPIå—
        if (inAPIBlock && currentBlock.content.trim()) {
          apiBlocks.push(currentBlock)
        }
        
        // å¼€å§‹æ–°çš„APIå—
        currentBlock = {
          title: apiMatch[1] || `${apiMatch[1] || apiMatch[0]} API`,
          content: line + '\n'
        }
        inAPIBlock = true
      } else if (inAPIBlock) {
        currentBlock.content += line + '\n'
        
        // å¦‚æœé‡åˆ°ä¸‹ä¸€ä¸ªAPIæˆ–ç« èŠ‚æ ‡é¢˜ï¼Œç»“æŸå½“å‰å—
        const nextApiMatch = lines[i + 1]?.match(/^#{1,4}\s*(.+?)\s*-\s*(GET|POST|PUT|DELETE|PATCH)\s+(.+)$/) ||
                            lines[i + 1]?.match(/^(GET|POST|PUT|DELETE|PATCH)\s+(.+)$/)
        const nextHeaderMatch = lines[i + 1]?.match(/^#+\s+(.+)$/)
        
        if (nextApiMatch || nextHeaderMatch) {
          apiBlocks.push(currentBlock)
          inAPIBlock = false
        }
      }
    }

    // ä¿å­˜æœ€åä¸€ä¸ªAPIå—
    if (inAPIBlock && currentBlock.content.trim()) {
      apiBlocks.push(currentBlock)
    }

    return apiBlocks
  }

  /**
   * æŒ‰APIæ¥å£åˆ†å—
   */
  private chunkByAPIs(apiBlocks: Array<{title: string, content: string}>, availableTokens: number): DocumentChunk[] {
    const chunks: DocumentChunk[] = []
    let currentChunk = ''
    let currentTokens = 0
    let chunkIndex = 0

    for (const apiBlock of apiBlocks) {
      const blockTokens = this.estimateTokenCount(apiBlock.content)
      
      // å¦‚æœå½“å‰å—åŠ ä¸Šè¿™ä¸ªAPIä¼šè¶…å‡ºé™åˆ¶ï¼Œå…ˆä¿å­˜å½“å‰å—
      if (currentTokens + blockTokens > availableTokens && currentChunk) {
        chunks.push({
          content: currentChunk.trim(),
          index: chunkIndex++,
          type: 'api',
          title: `APIåˆ†å— ${chunkIndex}`,
          estimatedTokens: currentTokens
        })
        currentChunk = ''
        currentTokens = 0
      }

      currentChunk += apiBlock.content + '\n'
      currentTokens += blockTokens
    }

    // ä¿å­˜æœ€åä¸€ä¸ªå—
    if (currentChunk.trim()) {
      chunks.push({
        content: currentChunk.trim(),
        index: chunkIndex,
        type: 'api',
        title: `APIåˆ†å— ${chunkIndex + 1}`,
        estimatedTokens: currentTokens
      })
    }

    return chunks
  }

  /**
   * æŒ‰æ®µè½åˆ†å— (å¸¦é‡å )
   */
  private chunkByParagraphs(content: string, availableTokens: number): DocumentChunk[] {
    const chunks: DocumentChunk[] = []
    const paragraphs = content.split(/\n\s*\n/).filter(p => p.trim())
    const overlapSize = Math.floor(availableTokens * 0.1) // 10% é‡å 
    
    let currentChunk = ''
    let currentTokens = 0
    let chunkIndex = 0
    let overlapContent = ''

    for (let i = 0; i < paragraphs.length; i++) {
      const paragraph = paragraphs[i]
      const paragraphTokens = this.estimateTokenCount(paragraph)
      
      if (currentTokens + paragraphTokens > availableTokens && currentChunk) {
        // ä¿å­˜å½“å‰å—
        chunks.push({
          content: currentChunk.trim(),
          index: chunkIndex++,
          type: 'content',
          title: `å†…å®¹åˆ†å— ${chunkIndex}`,
          estimatedTokens: currentTokens
        })
        
        // å‡†å¤‡é‡å å†…å®¹
        const sentences = currentChunk.split(/[ã€‚ï¼ï¼Ÿ.!?]\s*/).slice(-3) // ä¿ç•™æœ€å3å¥
        overlapContent = sentences.join('ã€‚') + (sentences.length > 0 ? 'ã€‚' : '')
        
        currentChunk = overlapContent + '\n' + paragraph + '\n'
        currentTokens = this.estimateTokenCount(currentChunk)
      } else {
        currentChunk += paragraph + '\n'
        currentTokens += paragraphTokens
      }
    }

    // ä¿å­˜æœ€åä¸€ä¸ªå—
    if (currentChunk.trim()) {
      chunks.push({
        content: currentChunk.trim(),
        index: chunkIndex,
        type: 'content',
        title: `å†…å®¹åˆ†å— ${chunkIndex + 1}`,
        estimatedTokens: currentTokens
      })
    }

    return chunks
  }

  /**
   * ä¼°ç®—Tokenæ•°é‡çš„è¾…åŠ©æ–¹æ³•
   */
  private estimateTokens(text: string): number {
    return this.estimateTokenCount(text)
  }

  // APIæ–‡æ¡£è§£æçš„ç³»ç»Ÿæç¤ºè¯
  private getAPIParsingPrompt(): string {
    return `# ç³»ç»Ÿè§’è‰²å®šä¹‰

ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„APIæ–‡æ¡£è§£æä¸“å®¶ï¼Œæ“…é•¿ä»å„ç§æ ¼å¼çš„æŠ€æœ¯æ–‡æ¡£ä¸­æå–å’Œæ ‡å‡†åŒ–APIæ¥å£ä¿¡æ¯ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·æä¾›çš„APIæ–‡æ¡£å†…å®¹è§£æä¸ºç»“æ„åŒ–çš„JSONæ ¼å¼ï¼Œç¡®ä¿ä¿¡æ¯çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ã€‚

# è§£æç›®æ ‡

è¯·å°†æä¾›çš„APIæ–‡æ¡£è§£æä¸ºæ ‡å‡†çš„JSONæ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹æ ¸å¿ƒä¿¡æ¯ï¼š
- APIæ¥å£çš„åŸºæœ¬ä¿¡æ¯ï¼ˆåç§°ã€æè¿°ã€HTTPæ–¹æ³•ã€è·¯å¾„ï¼‰
- è¯·æ±‚å‚æ•°ï¼ˆæŸ¥è¯¢å‚æ•°ã€è·¯å¾„å‚æ•°ã€è¯·æ±‚ä½“ï¼‰
- å“åº”æ ¼å¼å’ŒçŠ¶æ€ç 
- è®¤è¯è¦æ±‚
- ç¤ºä¾‹æ•°æ®

# è¾“å‡ºæ ¼å¼è¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡æœ¬è¯´æ˜ï¼š

{
  "apis": [
    {
      "name": "APIæ¥å£åç§°",
      "description": "æ¥å£åŠŸèƒ½æè¿°",
      "method": "GET|POST|PUT|DELETE|PATCH",
      "path": "/api/v1/example",
      "category": "æ¥å£åˆ†ç±»",
      "auth_required": true,
      "parameters": {
        "query": [
          {
            "name": "å‚æ•°å",
            "type": "string|number|boolean|array|object",
            "required": true,
            "description": "å‚æ•°æè¿°",
            "example": "ç¤ºä¾‹å€¼"
          }
        ],
        "path": [
          {
            "name": "å‚æ•°å",
            "type": "string|number",
            "required": true,
            "description": "è·¯å¾„å‚æ•°æè¿°"
          }
        ],
        "body": {
          "type": "object",
          "properties": {
            "å­—æ®µå": {
              "type": "æ•°æ®ç±»å‹",
              "description": "å­—æ®µæè¿°",
              "required": true
            }
          }
        }
      },
      "responses": {
        "200": {
          "description": "æˆåŠŸå“åº”",
          "example": {
            "success": true,
            "data": {},
            "message": "æ“ä½œæˆåŠŸ"
          }
        },
        "400": {
          "description": "è¯·æ±‚é”™è¯¯",
          "example": {
            "success": false,
            "error": "é”™è¯¯ä¿¡æ¯"
          }
        }
      },
      "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"]
    }
  ],
  "base_url": "https://api.example.com",
  "version": "v1",
  "auth_type": "Bearer Token|API Key|Basic Auth|None",
  "confidence": 0.95
}

# è§£æè§„åˆ™

## 1. æ¥å£è¯†åˆ«è§„åˆ™
- è¯†åˆ«HTTPæ–¹æ³•å…³é”®è¯ï¼šGETã€POSTã€PUTã€DELETEã€PATCH
- æå–APIè·¯å¾„ï¼šä»¥ / å¼€å¤´çš„URLè·¯å¾„
- è¯†åˆ«æ¥å£åç§°ï¼šé€šå¸¸åœ¨HTTPæ–¹æ³•é™„è¿‘æˆ–è·¯å¾„æ³¨é‡Šä¸­
- æå–æ¥å£æè¿°ï¼šæ¥å£åŠŸèƒ½è¯´æ˜æ–‡å­—

## 2. å‚æ•°è§£æè§„åˆ™
- æŸ¥è¯¢å‚æ•°ï¼šURLä¸­ ? åçš„å‚æ•°æˆ–æ–‡æ¡£ä¸­æ˜ç¡®æ ‡æ³¨çš„queryå‚æ•°
- è·¯å¾„å‚æ•°ï¼šURLè·¯å¾„ä¸­çš„ {param} æˆ– :param æ ¼å¼
- è¯·æ±‚ä½“å‚æ•°ï¼šPOST/PUTè¯·æ±‚çš„bodyå†…å®¹
- å‚æ•°ç±»å‹æ¨æ–­ï¼šæ ¹æ®ç¤ºä¾‹å€¼å’Œæè¿°æ¨æ–­æ•°æ®ç±»å‹

## 3. å“åº”æ ¼å¼è¯†åˆ«
- æå–HTTPçŠ¶æ€ç å’Œå¯¹åº”çš„å“åº”æè¿°
- è¯†åˆ«å“åº”æ•°æ®ç»“æ„å’Œç¤ºä¾‹
- æ ‡å‡†åŒ–é”™è¯¯å“åº”æ ¼å¼

## 4. è®¤è¯ä¿¡æ¯æå–
- è¯†åˆ«è®¤è¯æ–¹å¼ï¼šBearer Tokenã€API Keyã€Basic Authç­‰
- æå–è®¤è¯ç›¸å…³çš„headerä¿¡æ¯

# è´¨é‡æ£€æŸ¥æ¸…å•

åœ¨è¾“å‡ºæœ€ç»ˆç»“æœå‰ï¼Œè¯·ç¡®ä¿ï¼š
1. âœ… JSONæ ¼å¼æ­£ç¡®ï¼šè¯­æ³•æ— è¯¯ï¼Œå¯ä»¥è¢«æ­£ç¡®è§£æ
2. âœ… æ¥å£ä¿¡æ¯å®Œæ•´ï¼šnameã€methodã€pathå¿…é¡»å­˜åœ¨
3. âœ… å‚æ•°ç±»å‹å‡†ç¡®ï¼šæ ¹æ®ç¤ºä¾‹å’Œæè¿°æ¨æ–­æ­£ç¡®çš„æ•°æ®ç±»å‹
4. âœ… è·¯å¾„æ ¼å¼æ ‡å‡†ï¼šä»¥ / å¼€å¤´ï¼Œå‚æ•°ä½¿ç”¨ {param} æ ¼å¼
5. âœ… HTTPæ–¹æ³•æ­£ç¡®ï¼šä½¿ç”¨æ ‡å‡†çš„HTTPæ–¹æ³•å
6. âœ… è®¤è¯ä¿¡æ¯å‡†ç¡®ï¼šæ­£ç¡®è¯†åˆ«æ˜¯å¦éœ€è¦è®¤è¯
7. âœ… å“åº”æ ¼å¼ç»Ÿä¸€ï¼šåŒ…å«çŠ¶æ€ç å’Œç¤ºä¾‹æ•°æ®
8. âœ… æè¿°ä¿¡æ¯æ¸…æ™°ï¼šæä¾›æœ‰æ„ä¹‰çš„æ¥å£å’Œå‚æ•°æè¿°

# æ³¨æ„äº‹é¡¹

1. ä¸¥æ ¼éµå¾ªJSONæ ¼å¼ï¼šè¾“å‡ºå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONï¼Œä¸è¦åŒ…å«æ³¨é‡Šæˆ–é¢å¤–æ–‡æœ¬
2. ä¿æŒä¿¡æ¯å‡†ç¡®æ€§ï¼šå¦‚æœæ–‡æ¡£ä¿¡æ¯ä¸æ˜ç¡®ï¼Œä½¿ç”¨åˆç†çš„é»˜è®¤å€¼
3. ç»Ÿä¸€å‘½åè§„èŒƒï¼šæ¥å£åç§°ä½¿ç”¨ä¸­æ–‡ï¼Œå‚æ•°åç§°ä¿æŒåŸæ–‡
4. å®Œæ•´æ€§ä¼˜å…ˆï¼šå°½å¯èƒ½æå–æ‰€æœ‰å¯ç”¨ä¿¡æ¯
5. é”™è¯¯å¤„ç†ï¼šå¦‚æœæ— æ³•è§£ææŸä¸ªæ¥å£ï¼Œåœ¨å“åº”ä¸­è¯´æ˜åŸå› 

ç°åœ¨è¯·å¼€å§‹è§£æç”¨æˆ·æä¾›çš„APIæ–‡æ¡£å†…å®¹ã€‚`
  }

  // æ•°æ®åº“æ–‡æ¡£è§£æçš„ç³»ç»Ÿæç¤ºè¯
  private getDatabaseParsingPrompt(): string {
    return `# æ•°æ®åº“æ–‡æ¡£è§£æä¸“å®¶

ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åº“æ–‡æ¡£è§£æä¸“å®¶ï¼Œæ“…é•¿ä»å„ç§æ ¼å¼çš„æ•°æ®åº“è®¾è®¡æ–‡æ¡£ä¸­æå–å’Œæ ‡å‡†åŒ–æ•°æ®åº“ç»“æ„ä¿¡æ¯ã€‚

## è§£æç›®æ ‡

è¯·å°†æä¾›çš„æ•°æ®åº“æ–‡æ¡£è§£æä¸ºæ ‡å‡†çš„JSONæ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
- æ•°æ®è¡¨å®šä¹‰ï¼ˆè¡¨åã€å­—æ®µã€ç±»å‹ã€çº¦æŸç­‰ï¼‰
- ç´¢å¼•å®šä¹‰
- è¡¨å…³ç³»ï¼ˆå¤–é”®çº¦æŸï¼‰
- è¡¨æ³¨é‡Šå’Œå­—æ®µæ³¨é‡Š

## è¾“å‡ºæ ¼å¼è¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡æœ¬è¯´æ˜ï¼š

{
  "tables": [
    {
      "name": "table_name",
      "displayName": "è¡¨æ˜¾ç¤ºåç§°",
      "comment": "è¡¨æ³¨é‡Šè¯´æ˜",
      "engine": "InnoDB",
      "charset": "utf8mb4",
      "fields": [
        {
          "name": "å­—æ®µå",
          "type": "æ•°æ®ç±»å‹",
          "length": å­—æ®µé•¿åº¦,
          "nullable": true/false,
          "primaryKey": true/false,
          "autoIncrement": true/false,
          "unique": true/false,
          "defaultValue": "é»˜è®¤å€¼",
          "comment": "å­—æ®µæ³¨é‡Š"
        }
      ],
      "constraints": [
        {
          "type": "FOREIGN_KEY",
          "column": "å¤–é”®å­—æ®µ",
          "referencedTable": "å¼•ç”¨è¡¨",
          "referencedColumn": "å¼•ç”¨å­—æ®µ"
        }
      ],
      "indexes": [
        {
          "name": "ç´¢å¼•å",
          "columns": ["å­—æ®µ1", "å­—æ®µ2"],
          "type": "INDEX",
          "unique": false
        }
      ]
    }
  ],
  "relationships": [
    {
      "type": "one-to-many",
      "fromTable": "æºè¡¨",
      "fromColumn": "æºå­—æ®µ",
      "toTable": "ç›®æ ‡è¡¨", 
      "toColumn": "ç›®æ ‡å­—æ®µ"
    }
  ],
  "indexes": [
    {
      "name": "idx_name",
      "table": "è¡¨å",
      "columns": ["å­—æ®µåˆ—è¡¨"],
      "unique": false,
      "type": "BTREE"
    }
  ],
  "confidence": 0.95
}

## è§£æè§„åˆ™

### 1. è¡¨è¯†åˆ«è§„åˆ™
- è¯†åˆ«CREATE TABLEè¯­å¥
- è¯†åˆ«Markdownä¸­çš„è¡¨æ ‡é¢˜ï¼ˆå¦‚ï¼š#### 1.1 ç”¨æˆ·è¡¨ (users)ï¼‰
- æå–è¡¨åã€æ˜¾ç¤ºåç§°å’Œæ³¨é‡Š

### 2. å­—æ®µè§£æè§„åˆ™
- ä»SQL DDLè¯­å¥ä¸­æå–å­—æ®µå®šä¹‰
- ä»Markdownè¡¨æ ¼ä¸­æå–å­—æ®µä¿¡æ¯
- æ­£ç¡®è¯†åˆ«æ•°æ®ç±»å‹ï¼ˆVARCHAR, INT, BIGINT, TEXT, JSONç­‰ï¼‰
- æå–å­—æ®µé•¿åº¦ã€æ˜¯å¦å¯ç©ºã€é»˜è®¤å€¼ç­‰å±æ€§
- è¯†åˆ«ä¸»é”®ã€å¤–é”®ã€å”¯ä¸€çº¦æŸ

### 3. çº¦æŸå’Œç´¢å¼•
- è¯†åˆ«PRIMARY KEYã€FOREIGN KEYã€UNIQUEçº¦æŸ
- æå–INDEXã€KEYå®šä¹‰
- è¯†åˆ«å¤åˆç´¢å¼•å’Œå•åˆ—ç´¢å¼•

### 4. å…³ç³»è¯†åˆ«
- ä»FOREIGN KEYçº¦æŸä¸­æå–è¡¨å…³ç³»
- æ¨æ–­ä¸€å¯¹ä¸€ã€ä¸€å¯¹å¤šã€å¤šå¯¹å¤šå…³ç³»

### 5. æ•°æ®ç±»å‹æ ‡å‡†åŒ–
- ç»Ÿä¸€æ•°æ®ç±»å‹å‘½åï¼ˆå¦‚ï¼šVARCHAR, INT, BIGINTï¼‰
- æå–ç±»å‹é•¿åº¦å‚æ•°
- è¯†åˆ«æšä¸¾ç±»å‹çš„å¯é€‰å€¼

## è´¨é‡æ£€æŸ¥æ¸…å•

åœ¨è¾“å‡ºæœ€ç»ˆç»“æœå‰ï¼Œè¯·ç¡®ä¿ï¼š
1. âœ… JSONæ ¼å¼æ­£ç¡®ï¼Œè¯­æ³•æ— è¯¯
2. âœ… è¡¨åå’Œå­—æ®µåå‡†ç¡®æå–
3. âœ… æ•°æ®ç±»å‹æ­£ç¡®è¯†åˆ«å’Œæ ‡å‡†åŒ–
4. âœ… çº¦æŸå…³ç³»æ­£ç¡®è§£æ
5. âœ… ç´¢å¼•ä¿¡æ¯å®Œæ•´æå–
6. âœ… æ³¨é‡Šä¿¡æ¯å‡†ç¡®è·å–

## æ³¨æ„äº‹é¡¹

1. ä¸¥æ ¼éµå¾ªJSONæ ¼å¼ï¼šè¾“å‡ºå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSON
2. ä¿æŒä¿¡æ¯å‡†ç¡®æ€§ï¼šå¦‚æœä¿¡æ¯ä¸æ˜ç¡®ï¼Œä½¿ç”¨åˆç†çš„é»˜è®¤å€¼
3. ç»Ÿä¸€å‘½åè§„èŒƒï¼šè¡¨åä½¿ç”¨snake_caseï¼Œæ˜¾ç¤ºåç§°ä½¿ç”¨ä¸­æ–‡
4. å®Œæ•´æ€§ä¼˜å…ˆï¼šå°½å¯èƒ½æå–æ‰€æœ‰å¯ç”¨ä¿¡æ¯
5. é”™è¯¯å¤„ç†ï¼šå¦‚æœæ— æ³•è§£ææŸä¸ªè¡¨ï¼Œåœ¨å“åº”ä¸­è¯´æ˜åŸå› 

ç°åœ¨è¯·å¼€å§‹è§£æç”¨æˆ·æä¾›çš„æ•°æ®åº“æ–‡æ¡£å†…å®¹ã€‚`
  }

  /**
   * å¸¦é‡è¯•çš„APIè°ƒç”¨
   */
  private async callWithRetry<T>(
    apiCall: () => Promise<T>, 
    maxRetries: number = 3, 
    delayMs: number = 1000,
    context: string = ''
  ): Promise<T> {
    let lastError: Error | null = null
    
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`${context} - å°è¯• ${attempt}/${maxRetries}`)
        const result = await apiCall()
        
        // æ£€æŸ¥æ˜¯å¦æ˜¯tokené™åˆ¶é”™è¯¯
        if (this.isTokenLimitError(result)) {
          throw new Error('Tokené™åˆ¶é”™è¯¯ï¼Œéœ€è¦é‡æ–°åˆ†å—')
        }
        
        return result
      } catch (error: any) {
        lastError = error
        console.warn(`${context} - å°è¯• ${attempt}/${maxRetries} å¤±è´¥:`, error.message)
        
        // å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç›´æ¥æŠ›å‡ºé”™è¯¯
        if (attempt === maxRetries) {
          break
        }
        
        // æ ¹æ®é”™è¯¯ç±»å‹å†³å®šæ˜¯å¦é‡è¯•
        if (this.shouldRetry(error)) {
          const delay = delayMs * Math.pow(2, attempt - 1) // æŒ‡æ•°é€€é¿
          console.log(`${context} - ç­‰å¾… ${delay}ms åé‡è¯•...`)
          await new Promise(resolve => setTimeout(resolve, delay))
        } else {
          console.log(`${context} - é”™è¯¯ç±»å‹ä¸æ”¯æŒé‡è¯•ï¼Œç›´æ¥å¤±è´¥`)
          break
        }
      }
    }
    
    throw lastError || new Error(`${context} - é‡è¯• ${maxRetries} æ¬¡åä»ç„¶å¤±è´¥`)
  }

  /**
   * æ£€æŸ¥æ˜¯å¦æ˜¯tokené™åˆ¶é”™è¯¯
   */
  private isTokenLimitError(result: any): boolean {
    if (typeof result === 'string') {
      return result.toLowerCase().includes('token') && 
             (result.toLowerCase().includes('limit') || result.toLowerCase().includes('exceed'))
    }
    if (result?.error) {
      const errorStr = result.error.toLowerCase()
      return (errorStr.includes('token') && errorStr.includes('limit')) ||
             errorStr.includes('context length') ||
             errorStr.includes('maximum context')
    }
    return false
  }

  /**
   * åˆ¤æ–­é”™è¯¯æ˜¯å¦åº”è¯¥é‡è¯•
   */
  private shouldRetry(error: any): boolean {
    const message = error?.message?.toLowerCase() || ''
    const isNetworkError = message.includes('network') || 
                          message.includes('timeout') || 
                          message.includes('connection') ||
                          message.includes('fetch')
    
    const isServerError = error?.status >= 500 && error?.status < 600
    const isRateLimitError = error?.status === 429
    const isTokenError = this.isTokenLimitError(error)
    
    // ä¸é‡è¯•çš„æƒ…å†µ
    if (isTokenError || 
        error?.status === 401 || // è®¤è¯å¤±è´¥
        error?.status === 403 || // æƒé™ä¸è¶³
        error?.status === 404) { // èµ„æºä¸å­˜åœ¨
      return false
    }
    
    // åº”è¯¥é‡è¯•çš„æƒ…å†µ
    return isNetworkError || isServerError || isRateLimitError
  }

  // è°ƒç”¨Ollamaæœ¬åœ°æ¨¡å‹ - å¢å¼ºé”™è¯¯å¤„ç†
  private async callOllama(prompt: string, content: string): Promise<any> {
    const baseUrl = this.config.baseUrl || 'http://localhost:11434'
    
    return await this.callWithRetry(async () => {
      console.log('è°ƒç”¨Ollama API:', {
        url: `${baseUrl}/api/generate`,
        model: this.config.model
      })
      
      const response = await fetch(`${baseUrl}/api/generate`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: this.config.model,
          prompt: `${prompt}\n\næ–‡æ¡£å†…å®¹ï¼š\n${content}`,
          stream: false,
          options: {
            temperature: 0.1,
            top_p: 0.9
          }
        })
      })

      if (!response.ok) {
        const errorText = await response.text()
        console.error('Ollamaè¯·æ±‚å¤±è´¥:', response.status, response.statusText, errorText)
        
        // æ£€æŸ¥æ˜¯å¦æ˜¯tokené™åˆ¶é”™è¯¯
        if (errorText.includes('context length') || errorText.includes('token')) {
          throw new Error(`Tokené™åˆ¶é”™è¯¯: ${errorText}`)
        }
        
        const error = new Error(`Ollamaè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`)
        ;(error as any).status = response.status
        throw error
      }

      const result = await response.json()
      console.log('OllamaåŸå§‹å“åº”:', result)
      
      const parsedResult = this.parseAIResponse(result.response)
      
      // å¦‚æœè§£æç»“æœåŒ…å«é”™è¯¯ï¼Œè®°å½•ä½†ä¸æŠ›å‡ºå¼‚å¸¸
      if (!parsedResult.success && parsedResult.errors) {
        console.warn('AIè§£æåŒ…å«é”™è¯¯:', parsedResult.errors)
      }
      
      return parsedResult
    }, 3, 2000, 'Ollama APIè°ƒç”¨')
  }

  // è°ƒç”¨åœ¨çº¿API (DeepSeekã€OpenAIç­‰) - å¢å¼ºé”™è¯¯å¤„ç†
  private async callOnlineAPI(prompt: string, content: string): Promise<any> {
    const { provider, model, apiKey, baseUrl } = this.config
    
    return await this.callWithRetry(async () => {
      let url: string
      let headers: Record<string, string>
      let body: any

      switch (provider) {
        case 'deepseek':
          url = `${baseUrl || 'https://api.deepseek.com'}/v1/chat/completions`
          headers = {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
          }
          body = {
            model: model || 'deepseek-coder',
            messages: [
              { role: 'system', content: prompt },
              { role: 'user', content: content }
            ],
            temperature: 0.1
          }
          break

        case 'openai':
          url = `${baseUrl || 'https://api.openai.com'}/v1/chat/completions`
          headers = {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
          }
          body = {
            model: model || 'gpt-3.5-turbo',
            messages: [
              { role: 'system', content: prompt },
              { role: 'user', content: content }
            ],
            temperature: 0.1
          }
          break

        default:
          throw new Error(`ä¸æ”¯æŒçš„AIæä¾›å•†: ${provider}`)
      }

      const response = await fetch(url, {
        method: 'POST',
        headers,
        body: JSON.stringify(body)
      })

      if (!response.ok) {
        const errorText = await response.text()
        console.error('åœ¨çº¿APIè¯·æ±‚å¤±è´¥:', response.status, response.statusText, errorText)
        
        // æ£€æŸ¥æ˜¯å¦æ˜¯tokené™åˆ¶é”™è¯¯
        if (errorText.includes('token') || errorText.includes('context_length')) {
          throw new Error(`Tokené™åˆ¶é”™è¯¯: ${errorText}`)
        }
        
        const error = new Error(`APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`)
        ;(error as any).status = response.status
        throw error
      }

      const result = await response.json()
      const content = result.choices?.[0]?.message?.content
      
      if (!content) {
        throw new Error('AIå“åº”æ ¼å¼é”™è¯¯: æœªæ‰¾åˆ°æœ‰æ•ˆå†…å®¹')
      }

      const parsedResult = this.parseAIResponse(content)
      
      // å¦‚æœè§£æç»“æœåŒ…å«é”™è¯¯ï¼Œè®°å½•ä½†ä¸æŠ›å‡ºå¼‚å¸¸
      if (!parsedResult.success && parsedResult.errors) {
        console.warn('åœ¨çº¿APIè§£æåŒ…å«é”™è¯¯:', parsedResult.errors)
      }
      
      return parsedResult
    }, 3, 2000, `${provider}åœ¨çº¿APIè°ƒç”¨`)
  }

  // è§£æAIå“åº”
  private parseAIResponse(response: string): any {
    try {
      console.log('ğŸ” å¼€å§‹è§£æAIå“åº”...')
      console.log('ğŸ“ åŸå§‹AIå“åº”é•¿åº¦:', response.length)
      console.log('ğŸ“„ åŸå§‹AIå“åº”å‰500å­—ç¬¦:', response.substring(0, 500))
      console.log('ğŸ“„ åŸå§‹AIå“åº”å100å­—ç¬¦:', response.substring(Math.max(0, response.length - 100)))
      
      // æ·±åº¦æ¸…ç†å“åº”å†…å®¹
      let cleanedResponse = response
        .replace(/^\uFEFF/, '') // ç§»é™¤BOM
        .replace(/^[\s\r\n]+/, '') // ç§»é™¤å¼€å¤´çš„æ‰€æœ‰ç©ºç™½å­—ç¬¦
        .replace(/[\s\r\n]+$/, '') // ç§»é™¤ç»“å°¾çš„æ‰€æœ‰ç©ºç™½å­—ç¬¦
      
      console.log('ğŸ§¹ æ¸…ç†åå“åº”å‰200å­—ç¬¦:', cleanedResponse.substring(0, 200))
      
      // ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
      cleanedResponse = cleanedResponse
        .replace(/^```json\s*/, '')
        .replace(/^```\s*/, '')
        .replace(/\s*```$/, '')
      
      console.log('ğŸ”¤ ç§»é™¤markdownå:', cleanedResponse.substring(0, 200))
      
      // ç§»é™¤å¯èƒ½çš„æ–‡æœ¬è¯´æ˜
      cleanedResponse = cleanedResponse
        .replace(/^[^{\[]*(?=[{\[])/s, '') // ç§»é™¤JSON/æ•°ç»„å‰çš„æ‰€æœ‰æ–‡æœ¬
        .replace(/(?<=[}\]])[^}\]]*$/s, '') // ç§»é™¤JSON/æ•°ç»„åçš„æ‰€æœ‰æ–‡æœ¬
      
      console.log('âœ¨ æœ€ç»ˆæ¸…ç†åçš„å“åº”é•¿åº¦:', cleanedResponse.length)
      console.log('âœ¨ æœ€ç»ˆæ¸…ç†åçš„å“åº”:', cleanedResponse.substring(0, 300) + (cleanedResponse.length > 300 ? '...' : ''))
      
      // æ£€æŸ¥æ˜¯å¦ä¸ºç©º
      if (!cleanedResponse) {
        throw new Error('æ¸…ç†åçš„å“åº”ä¸ºç©º')
      }
      
      // å°è¯•ç›´æ¥è§£æ
      try {
        const parsed = JSON.parse(cleanedResponse)
        console.log('âœ… ç›´æ¥è§£ææˆåŠŸ:', {
          type: typeof parsed,
          hasApis: parsed?.hasOwnProperty('apis'),
          apisLength: Array.isArray(parsed?.apis) ? parsed.apis.length : 'not array',
          keys: Object.keys(parsed || {})
        })
        return parsed
      } catch (directError) {
        console.log('âŒ ç›´æ¥è§£æå¤±è´¥:', directError.message)
      }
      
      // å°è¯•æå–JSONå¯¹è±¡ï¼ˆæ›´å®½æ¾çš„åŒ¹é…ï¼‰
      const jsonMatch = cleanedResponse.match(/\{[\s\S]*\}/)
      if (jsonMatch) {
        console.log('ğŸ¯ æ‰¾åˆ°JSONå¯¹è±¡åŒ¹é…:', jsonMatch[0].substring(0, 100) + '...')
        try {
          const parsed = JSON.parse(jsonMatch[0])
          console.log('âœ… å¯¹è±¡æå–è§£ææˆåŠŸ:', {
            type: typeof parsed,
            hasApis: parsed?.hasOwnProperty('apis'),
            apisLength: Array.isArray(parsed?.apis) ? parsed.apis.length : 'not array',
            keys: Object.keys(parsed || {})
          })
          return parsed
        } catch (jsonError) {
          console.log('âŒ å¯¹è±¡æå–è§£æå¤±è´¥:', jsonError.message)
        }
      } else {
        console.log('âš ï¸ æœªæ‰¾åˆ°JSONå¯¹è±¡åŒ¹é…')
      }
      
      // å°è¯•æŸ¥æ‰¾æ•°ç»„æ ¼å¼
      const arrayMatch = cleanedResponse.match(/\[[\s\S]*\]/)
      if (arrayMatch) {
        console.log('ğŸ¯ æ‰¾åˆ°æ•°ç»„åŒ¹é…:', arrayMatch[0].substring(0, 100) + '...')
        try {
          const parsed = JSON.parse(arrayMatch[0])
          console.log('âœ… æ•°ç»„æå–è§£ææˆåŠŸ:', {
            type: typeof parsed,
            isArray: Array.isArray(parsed),
            length: Array.isArray(parsed) ? parsed.length : 'not array'
          })
          return { apis: parsed }
        } catch (arrayError) {
          console.log('âŒ æ•°ç»„æå–è§£æå¤±è´¥:', arrayError.message)
        }
      } else {
        console.log('âš ï¸ æœªæ‰¾åˆ°æ•°ç»„åŒ¹é…')
      }
      
      throw new Error('æ— æ³•ä»å“åº”ä¸­æå–æœ‰æ•ˆçš„JSON')
    } catch (error) {
      console.error('è§£æAIå“åº”å¤±è´¥:', error)
      console.error('å®Œæ•´å“åº”å†…å®¹:', JSON.stringify(response))
      
      // è¿”å›ä¸€ä¸ªé»˜è®¤çš„é”™è¯¯å“åº”è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
      return {
        apis: [],
        success: false,
        errors: [`AIå“åº”è§£æå¤±è´¥: ${error.message}ã€‚è¯·æ£€æŸ¥AIæ¨¡å‹é…ç½®æˆ–å°è¯•å…¶ä»–æ¨¡å‹ã€‚`],
        confidence: 0
      }
    }
  }


  // å¸¦è¿›åº¦çš„æ•°æ®åº“æ–‡æ¡£è§£æ
  async parseDatabaseDocumentWithProgress(
    content: string,
    onProgress?: (progress: { current: number; total: number; chunk?: DocumentChunk }) => void
  ): Promise<ParsedDatabaseDocument> {
    try {
      console.log('ğŸ” å¼€å§‹å¸¦è¿›åº¦çš„æ•°æ®åº“æ–‡æ¡£è§£æ:', {
        provider: this.config.provider,
        model: this.config.model,
        contentLength: content.length
      })
      
      // å¦‚æœæ˜¯æ¨¡æ‹Ÿæ¨¡å¼ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
      if (this.config.provider === 'mock') {
        const { mockParseDatabaseDocumentWithProgress } = await import('@/services/mockAiService')
        return await mockParseDatabaseDocumentWithProgress(content, onProgress)
      }

      // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å—å¤„ç†
      const chunks = this.chunkDocument(content)
      
      if (chunks.length === 1) {
        // å•å—å¤„ç†ï¼Œç›´æ¥æŠ¥å‘Šè¿›åº¦
        onProgress?.({ current: 0, total: 1, chunk: chunks[0] })
        const result = await this.parseSingleDatabaseChunk(chunks[0])
        onProgress?.({ current: 1, total: 1 })
        return result
      } else {
        // å¤šå—å¤„ç†ï¼Œé€ä¸ªæŠ¥å‘Šè¿›åº¦
        return await this.parseMultipleDatabaseChunksWithProgress(chunks, onProgress)
      }
    } catch (error: any) {
      console.error('æ•°æ®åº“æ–‡æ¡£è§£æå¤±è´¥:', error)
      return {
        tables: [],
        relationships: [],
        indexes: [],
        success: false,
        errors: [`æ•°æ®åº“æ–‡æ¡£è§£æå¤±è´¥: ${error.message}`],
        confidence: 0
      }
    }
  }

  // è§£æå•ä¸ªæ•°æ®åº“æ–‡æ¡£åˆ†å—
  private async parseSingleDatabaseChunk(chunk: DocumentChunk): Promise<ParsedDatabaseDocument> {
    console.log(`ğŸ” å¼€å§‹è§£ææ•°æ®åº“åˆ†å— ${chunk.index + 1}:`, {
      title: chunk.title,
      contentLength: chunk.content.length,
      estimatedTokens: chunk.estimatedTokens,
      provider: this.config.provider,
      model: this.config.model
    })

    const prompt = this.getDatabaseParsingPrompt()
    let result: any

    try {
      if (this.config.provider === 'ollama') {
        console.log(`ğŸ“¡ è°ƒç”¨Ollama APIè§£ææ•°æ®åº“...`)
        result = await this.callOllama(prompt, chunk.content)
      } else {
        console.log(`ğŸ“¡ è°ƒç”¨åœ¨çº¿APIè§£ææ•°æ®åº“...`)
        result = await this.callOnlineAPI(prompt, chunk.content)
      }
      
      console.log(`ğŸ¤– æ•°æ®åº“AIå“åº”åŸå§‹ç»“æœ:`, {
        hasResult: !!result,
        resultType: typeof result,
        hasTables: result?.hasOwnProperty('tables'),
        tablesLength: Array.isArray(result?.tables) ? result.tables.length : 'not array',
        hasIndexes: result?.hasOwnProperty('indexes'),
        indexesLength: Array.isArray(result?.indexes) ? result.indexes.length : 'not array'
      })
      
    } catch (error: any) {
      console.error(`âŒ æ•°æ®åº“åˆ†å— ${chunk.index + 1} AIè°ƒç”¨å¼‚å¸¸:`, error)
      return {
        tables: [],
        relationships: [],
        indexes: [],
        success: false,
        errors: [`AIè°ƒç”¨å¼‚å¸¸: ${error.message}`],
        confidence: 0
      }
    }
    
    // æ£€æŸ¥ç»“æœæ˜¯å¦åŒ…å«é”™è¯¯
    if (!result.success && result.errors) {
      console.warn(`âš ï¸ æ•°æ®åº“åˆ†å— ${chunk.index + 1} AIè§£æè¿”å›é”™è¯¯:`, result.errors)
      return {
        tables: [],
        relationships: [],
        indexes: [],
        success: false,
        errors: result.errors,
        confidence: 0
      }
    }

    // å¤„ç†è§£æç»“æœ
    const tables = result.tables || []
    const relationships = result.relationships || []
    const indexes = result.indexes || []

    console.log(`âœ… æ•°æ®åº“åˆ†å— ${chunk.index + 1} è§£æå®Œæˆ:`, {
      tablesCount: tables.length,
      relationshipsCount: relationships.length,
      indexesCount: indexes.length,
      success: tables.length > 0
    })

    return {
      tables,
      relationships,
      indexes,
      success: tables.length > 0,
      errors: tables.length === 0 ? ['æœªèƒ½è§£æåˆ°ä»»ä½•æ•°æ®è¡¨'] : [],
      confidence: result.confidence || 0.8
    }
  }

  // è§£æå¤šä¸ªæ•°æ®åº“æ–‡æ¡£åˆ†å—å¹¶åˆå¹¶ç»“æœ
  private async parseMultipleDatabaseChunks(chunks: DocumentChunk[]): Promise<ParsedDatabaseDocument> {
    console.log(`ğŸ”„ æ•°æ®åº“æ–‡æ¡£è¿‡é•¿ï¼Œåˆ†ä¸º${chunks.length}ä¸ªå—è¿›è¡Œå¤„ç†`)
    
    const results: ParsedDatabaseDocument[] = []
    const errors: string[] = []
    let successCount = 0
    let totalConfidence = 0

    // åˆ†ç»„å¤„ç†ï¼Œé¿å…å¹¶å‘è¿‡å¤š
    const chunkGroups = []
    const groupSize = 3
    for (let i = 0; i < chunks.length; i += groupSize) {
      chunkGroups.push(chunks.slice(i, i + groupSize))
    }

    for (const chunkGroup of chunkGroups) {
      const promises = chunkGroup.map(async (chunk) => {
        try {
          console.log(`ğŸ” å¤„ç†æ•°æ®åº“åˆ†å— ${chunk.index + 1}/${chunks.length}: ${chunk.title}`)
          
          const result = await this.parseSingleDatabaseChunk(chunk)
          
          if (result.success && result.tables.length > 0) {
            console.log(`âœ… æ•°æ®åº“åˆ†å— ${chunk.index + 1} è§£ææˆåŠŸ: ${result.tables.length} ä¸ªè¡¨`)
            successCount++
            totalConfidence += result.confidence
            return result
          } else {
            console.warn(`âŒ æ•°æ®åº“åˆ†å— ${chunk.index + 1} è§£æå¤±è´¥:`, result.errors)
            errors.push(`åˆ†å—${chunk.index + 1}è§£æå¤±è´¥: ${result.errors.join(', ')}`)
            return result
          }
        } catch (error: any) {
          console.error(`âŒ æ•°æ®åº“åˆ†å— ${chunk.index + 1} å¤„ç†å¼‚å¸¸:`, error)
          errors.push(`åˆ†å—${chunk.index + 1}å¤„ç†å¼‚å¸¸: ${error.message}`)
          return {
            tables: [],
            relationships: [],
            indexes: [],
            success: false,
            errors: [error.message],
            confidence: 0
          }
        }
      })

      const groupResults = await Promise.all(promises)
      results.push(...groupResults)
      
      // æ·»åŠ å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„APIè°ƒç”¨
      if (chunkGroups.indexOf(chunkGroup) < chunkGroups.length - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000))
      }
    }

    // åˆå¹¶æ‰€æœ‰æˆåŠŸçš„ç»“æœ
    const allTables = []
    const allRelationships = []
    const allIndexes = []

    for (const result of results) {
      if (result.success) {
        allTables.push(...result.tables)
        allRelationships.push(...result.relationships)
        allIndexes.push(...result.indexes)
      }
    }

    // å»é‡å¤„ç†
    const uniqueTables = this.deduplicateTables(allTables)
    const uniqueRelationships = this.deduplicateRelationships(allRelationships)
    const uniqueIndexes = this.deduplicateIndexes(allIndexes)

    console.log(`ğŸ¯ æ•°æ®åº“å¤šåˆ†å—è§£æå®Œæˆ:`, {
      totalChunks: chunks.length,
      successfulChunks: successCount,
      finalTables: uniqueTables.length,
      finalRelationships: uniqueRelationships.length,
      finalIndexes: uniqueIndexes.length
    })

    return {
      tables: uniqueTables,
      relationships: uniqueRelationships,
      indexes: uniqueIndexes,
      success: uniqueTables.length > 0,
      errors: uniqueTables.length === 0 ? errors : [],
      confidence: successCount > 0 ? totalConfidence / successCount : 0
    }
  }

  // å¸¦è¿›åº¦çš„è§£æå¤šä¸ªæ•°æ®åº“æ–‡æ¡£åˆ†å—å¹¶åˆå¹¶ç»“æœ
  private async parseMultipleDatabaseChunksWithProgress(
    chunks: DocumentChunk[],
    onProgress?: (progress: { current: number; total: number; chunk?: DocumentChunk }) => void
  ): Promise<ParsedDatabaseDocument> {
    console.log(`ğŸ”„ æ•°æ®åº“æ–‡æ¡£è¿‡é•¿ï¼Œåˆ†ä¸º${chunks.length}ä¸ªå—è¿›è¡Œå¤„ç†ï¼ˆå¸¦è¿›åº¦ï¼‰`)
    
    const results: ParsedDatabaseDocument[] = []
    const errors: string[] = []
    let successCount = 0
    let totalConfidence = 0

    // é€ä¸ªå¤„ç†ï¼Œä¿è¯è¿›åº¦æŠ¥å‘Šçš„å‡†ç¡®æ€§
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i]
      
      // æŠ¥å‘Šå½“å‰è¿›åº¦
      onProgress?.({
        current: i,
        total: chunks.length,
        chunk
      })
      
      try {
        console.log(`ğŸ” å¤„ç†æ•°æ®åº“åˆ†å— ${i + 1}/${chunks.length}: ${chunk.title}`)
        
        const result = await this.parseSingleDatabaseChunk(chunk)
        
        if (result.success && result.tables.length > 0) {
          console.log(`âœ… æ•°æ®åº“åˆ†å— ${i + 1} è§£ææˆåŠŸ: ${result.tables.length} ä¸ªè¡¨`)
          successCount++
          totalConfidence += result.confidence
          results.push(result)
        } else {
          console.warn(`âŒ æ•°æ®åº“åˆ†å— ${i + 1} è§£æå¤±è´¥:`, result.errors)
          errors.push(`åˆ†å—${i + 1}è§£æå¤±è´¥: ${result.errors.join(', ')}`)
          results.push(result)
        }
      } catch (error: any) {
        console.error(`âŒ æ•°æ®åº“åˆ†å— ${i + 1} å¤„ç†å¼‚å¸¸:`, error)
        errors.push(`åˆ†å—${i + 1}å¤„ç†å¼‚å¸¸: ${error.message}`)
        results.push({
          tables: [],
          relationships: [],
          indexes: [],
          success: false,
          errors: [error.message],
          confidence: 0
        })
      }
      
      // æ·»åŠ å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„APIè°ƒç”¨
      if (i < chunks.length - 1) {
        await new Promise(resolve => setTimeout(resolve, 500))
      }
    }

    // æŠ¥å‘Šå®Œæˆè¿›åº¦
    onProgress?.({
      current: chunks.length,
      total: chunks.length
    })

    // åˆå¹¶æ‰€æœ‰æˆåŠŸçš„ç»“æœ
    const allTables = []
    const allRelationships = []
    const allIndexes = []

    for (const result of results) {
      if (result.success) {
        allTables.push(...result.tables)
        allRelationships.push(...result.relationships)
        allIndexes.push(...result.indexes)
      }
    }

    // å»é‡å¤„ç†
    const uniqueTables = this.deduplicateTables(allTables)
    const uniqueRelationships = this.deduplicateRelationships(allRelationships)
    const uniqueIndexes = this.deduplicateIndexes(allIndexes)

    console.log(`ğŸ¯ æ•°æ®åº“å¤šåˆ†å—è§£æå®Œæˆ:`, {
      totalChunks: chunks.length,
      successfulChunks: successCount,
      finalTables: uniqueTables.length,
      finalRelationships: uniqueRelationships.length,
      finalIndexes: uniqueIndexes.length
    })

    return {
      tables: uniqueTables,
      relationships: uniqueRelationships,
      indexes: uniqueIndexes,
      success: uniqueTables.length > 0,
      errors: uniqueTables.length === 0 ? errors : [],
      confidence: successCount > 0 ? totalConfidence / successCount : 0
    }
  }

  // æ•°æ®åº“è¡¨å»é‡
  private deduplicateTables(tables: any[]): any[] {
    const seen = new Set()
    return tables.filter(table => {
      const key = table.name.toLowerCase()
      if (seen.has(key)) {
        console.log(`ğŸ”„ å‘ç°é‡å¤è¡¨å®šä¹‰: ${table.name}ï¼Œå·²å»é‡`)
        return false
      }
      seen.add(key)
      return true
    })
  }

  // å…³ç³»å»é‡
  private deduplicateRelationships(relationships: any[]): any[] {
    const seen = new Set()
    return relationships.filter(rel => {
      const key = `${rel.fromTable}.${rel.fromColumn}-${rel.toTable}.${rel.toColumn}`
      if (seen.has(key)) return false
      seen.add(key)
      return true
    })
  }

  // ç´¢å¼•å»é‡
  private deduplicateIndexes(indexes: any[]): any[] {
    const seen = new Set()
    return indexes.filter(idx => {
      const key = `${idx.table}.${idx.name}`
      if (seen.has(key)) return false
      seen.add(key)
      return true
    })
  }

  // è§£æAPIæ–‡æ¡£ - æ”¯æŒåˆ†å—å¤„ç†
  async parseAPIDocument(content: string, projectId: string): Promise<ParsedAPIDocument> {
    try {
      console.log('å¼€å§‹è§£æAPIæ–‡æ¡£:', {
        provider: this.config.provider,
        model: this.config.model,
        contentLength: content.length
      })
      
      // å¦‚æœæ˜¯æ¨¡æ‹Ÿæ¨¡å¼ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
      if (this.config.provider === 'mock') {
        const { mockParseAPIDocument } = await import('@/services/mockAiService')
        const mockResult = await mockParseAPIDocument(content, projectId)
        return {
          apis: mockResult.apis || [],
          success: mockResult.success,
          errors: mockResult.errors,
          confidence: mockResult.confidence
        }
      }

      // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å—å¤„ç†
      const chunks = this.chunkDocument(content)
      
      if (chunks.length === 1) {
        // å•å—å¤„ç†
        return await this.parseSingleChunk(chunks[0], projectId)
      } else {
        // å¤šå—å¤„ç†
        return await this.parseMultipleChunks(chunks, projectId)
      }
    } catch (error: any) {
      return {
        apis: [],
        success: false,
        errors: [error.message || 'è§£æå¤±è´¥'],
        confidence: 0
      }
    }
  }

  /**
   * è§£æå•ä¸ªåˆ†å—
   */
  private async parseSingleChunk(chunk: DocumentChunk, projectId: string): Promise<ParsedAPIDocument> {
    console.log(`ğŸ” å¼€å§‹è§£æåˆ†å— ${chunk.index + 1}:`, {
      title: chunk.title,
      contentLength: chunk.content.length,
      estimatedTokens: chunk.estimatedTokens,
      contentPreview: chunk.content.substring(0, 300) + (chunk.content.length > 300 ? '...' : ''),
      provider: this.config.provider,
      model: this.config.model
    })

    const prompt = this.getAPIParsingPrompt()
    let result: any

    try {
      if (this.config.provider === 'ollama') {
        console.log(`ğŸ“¡ è°ƒç”¨Ollama API...`)
        result = await this.callOllama(prompt, chunk.content)
      } else {
        console.log(`ğŸ“¡ è°ƒç”¨åœ¨çº¿API...`)
        result = await this.callOnlineAPI(prompt, chunk.content)
      }
      
      console.log(`ğŸ¤– AIå“åº”åŸå§‹ç»“æœ:`, {
        hasResult: !!result,
        resultType: typeof result,
        hasSuccess: result?.hasOwnProperty('success'),
        success: result?.success,
        hasApis: result?.hasOwnProperty('apis'),
        apisType: typeof result?.apis,
        apisLength: Array.isArray(result?.apis) ? result.apis.length : 'not array',
        hasErrors: result?.hasOwnProperty('errors'),
        errors: result?.errors,
        rawResultPreview: JSON.stringify(result).substring(0, 500) + '...'
      })
      
    } catch (error: any) {
      console.error(`âŒ åˆ†å— ${chunk.index + 1} AIè°ƒç”¨å¼‚å¸¸:`, error)
      return {
        apis: [],
        success: false,
        errors: [`AIè°ƒç”¨å¼‚å¸¸: ${error.message}`],
        confidence: 0
      }
    }
    
    // æ£€æŸ¥ç»“æœæ˜¯å¦åŒ…å«é”™è¯¯
    if (!result.success && result.errors) {
      console.warn(`âš ï¸ åˆ†å— ${chunk.index + 1} AIè§£æè¿”å›é”™è¯¯:`, result.errors)
      return {
        apis: [],
        success: false,
        errors: result.errors,
        confidence: 0
      }
    }

    // è½¬æ¢ä¸ºæ ‡å‡†APIæ ¼å¼
    console.log(`ğŸ”„ å¼€å§‹è½¬æ¢APIæ ¼å¼ï¼ŒåŸå§‹APIs:`, result.apis)
    const apis: API[] = result.apis?.map((api: any, index: number) => {
      console.log(`ğŸ“ å¤„ç†API ${index + 1}:`, {
        originalApi: api,
        hasName: !!api.name,
        hasMethod: !!api.method,
        hasPath: !!api.path
      })

      return {
        id: `ai-parsed-${Date.now()}-${index}`,
        projectId,
        name: api.name || 'æœªå‘½åAPI',
        description: api.description || '',
        method: this.normalizeHTTPMethod(api.method),
        path: api.path || '/',
        status: APIStatus.NOT_STARTED,
        createdAt: new Date().toISOString(),
        updatedAt: new Date().toISOString()
      }
    }) || []

    console.log(`âœ… åˆ†å— ${chunk.index + 1} è§£æå®Œæˆ:`, {
      finalApisCount: apis.length,
      success: apis.length > 0,
      apisPreview: apis.map(api => ({ name: api.name, method: api.method, path: api.path }))
    })

    return {
      apis,
      success: apis.length > 0,
      errors: apis.length === 0 ? ['æœªèƒ½è§£æåˆ°ä»»ä½•APIæ¥å£'] : [],
      confidence: result.confidence || 0.8
    }
  }

  /**
   * è§£æå¤šä¸ªåˆ†å—å¹¶åˆå¹¶ç»“æœ
   */
  private async parseMultipleChunks(chunks: DocumentChunk[], projectId: string): Promise<ParsedAPIDocument> {
    console.log(`æ–‡æ¡£è¿‡é•¿ï¼Œåˆ†ä¸º${chunks.length}ä¸ªå—è¿›è¡Œå¤„ç†`)
    
    const results: ParsedAPIDocument[] = []
    const errors: string[] = []
    let totalAPIs: API[] = []
    let successCount = 0
    let totalConfidence = 0

    // å¹¶è¡Œå¤„ç†æ‰€æœ‰åˆ†å—ï¼ˆé™åˆ¶å¹¶å‘æ•°ï¼‰
    const concurrency = 3 // æœ€å¤§å¹¶å‘æ•°
    const chunkGroups = []
    
    for (let i = 0; i < chunks.length; i += concurrency) {
      chunkGroups.push(chunks.slice(i, i + concurrency))
    }

    for (const chunkGroup of chunkGroups) {
      const promises = chunkGroup.map(async (chunk, index) => {
        try {
          console.log(`å¤„ç†åˆ†å— ${chunk.index + 1}/${chunks.length}: ${chunk.title} (${chunk.estimatedTokens} tokens)`)
          
          const result = await this.parseSingleChunk(chunk, projectId)
          
          if (result.success && result.apis.length > 0) {
            console.log(`åˆ†å— ${chunk.index + 1} è§£ææˆåŠŸ: ${result.apis.length} ä¸ªAPI`)
            successCount++
            totalConfidence += result.confidence
            
            // ä¸ºAPIæ·»åŠ åˆ†å—ä¿¡æ¯
            const chunkAPIs = result.apis.map(api => ({
              ...api,
              id: `chunk-${chunk.index}-${api.id}`,
              description: `[åˆ†å—${chunk.index + 1}] ${api.description || ''}`
            }))
            
            return {
              ...result,
              apis: chunkAPIs
            }
          } else {
            console.warn(`åˆ†å— ${chunk.index + 1} è§£æå¤±è´¥:`, result.errors)
            errors.push(`åˆ†å—${chunk.index + 1}è§£æå¤±è´¥: ${result.errors.join(', ')}`)
            return result
          }
        } catch (error: any) {
          console.error(`åˆ†å— ${chunk.index + 1} å¤„ç†å¼‚å¸¸:`, error)
          errors.push(`åˆ†å—${chunk.index + 1}å¤„ç†å¼‚å¸¸: ${error.message}`)
          return {
            apis: [],
            success: false,
            errors: [error.message],
            confidence: 0
          }
        }
      })

      const groupResults = await Promise.all(promises)
      results.push(...groupResults)
      
      // æ·»åŠ å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹çš„APIè°ƒç”¨
      if (chunkGroups.indexOf(chunkGroup) < chunkGroups.length - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000))
      }
    }

    // åˆå¹¶æ‰€æœ‰æˆåŠŸçš„ç»“æœ
    for (const result of results) {
      if (result.success && result.apis.length > 0) {
        totalAPIs.push(...result.apis)
      }
    }

    // å»é‡å¤„ç† - åŸºäºnameå’Œpathçš„ç›¸ä¼¼æ€§
    const uniqueAPIs = this.deduplicateAPIs(totalAPIs)
    
    const averageConfidence = successCount > 0 ? totalConfidence / successCount : 0
    const hasErrors = errors.length > 0
    
    console.log(`åˆ†å—è§£æå®Œæˆ: ${chunks.length}ä¸ªåˆ†å—, ${successCount}ä¸ªæˆåŠŸ, ${uniqueAPIs.length}ä¸ªAPI (å»é‡å)`)

    return {
      apis: uniqueAPIs,
      success: uniqueAPIs.length > 0,
      errors: hasErrors ? errors : (uniqueAPIs.length === 0 ? ['æ‰€æœ‰åˆ†å—éƒ½æœªèƒ½è§£æåˆ°APIæ¥å£'] : []),
      confidence: averageConfidence
    }
  }

  /**
   * APIå»é‡å¤„ç†
   */
  private deduplicateAPIs(apis: API[]): API[] {
    const uniqueAPIs: API[] = []
    const seenAPIs = new Set<string>()

    for (const api of apis) {
      // åˆ›å»ºå”¯ä¸€æ ‡è¯†ç¬¦
      const key = `${api.method}:${api.path}:${api.name}`.toLowerCase()
      
      if (!seenAPIs.has(key)) {
        seenAPIs.add(key)
        uniqueAPIs.push(api)
      } else {
        // å¦‚æœé‡å¤ï¼Œåˆå¹¶æè¿°ä¿¡æ¯
        const existingAPI = uniqueAPIs.find(existing => 
          existing.method === api.method && 
          existing.path === api.path && 
          existing.name === api.name
        )
        
        if (existingAPI && api.description && api.description !== existingAPI.description) {
          existingAPI.description = `${existingAPI.description}\n\nè¡¥å……ä¿¡æ¯: ${api.description}`
        }
      }
    }

    return uniqueAPIs
  }

  /**
   * è·å–åˆ†å—å¤„ç†è¿›åº¦çš„å›è°ƒæ¥å£
   */
  async parseAPIDocumentWithProgress(
    content: string, 
    projectId: string,
    onProgress?: (progress: { current: number, total: number, chunk: DocumentChunk }) => void
  ): Promise<ParsedAPIDocument> {
    const chunks = this.chunkDocument(content)
    
    if (chunks.length === 1) {
      onProgress?.({ current: 1, total: 1, chunk: chunks[0] })
      return await this.parseSingleChunk(chunks[0], projectId)
    }
    
    console.log(`å¼€å§‹åˆ†å—å¤„ç†: ${chunks.length} ä¸ªåˆ†å—`)
    
    const results: ParsedAPIDocument[] = []
    const errors: string[] = []
    let totalAPIs: API[] = []
    let successCount = 0
    let totalConfidence = 0

    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i]
      onProgress?.({ current: i + 1, total: chunks.length, chunk })
      
      try {
        const result = await this.parseSingleChunk(chunk, projectId)
        results.push(result)
        
        if (result.success && result.apis.length > 0) {
          successCount++
          totalConfidence += result.confidence
          totalAPIs.push(...result.apis.map(api => ({
            ...api,
            id: `chunk-${i}-${api.id}`,
            description: `[åˆ†å—${i + 1}] ${api.description || ''}`
          })))
        } else {
          errors.push(`åˆ†å—${i + 1}è§£æå¤±è´¥: ${result.errors.join(', ')}`)
        }
        
        // æ·»åŠ å»¶è¿Ÿ
        if (i < chunks.length - 1) {
          await new Promise(resolve => setTimeout(resolve, 500))
        }
      } catch (error: any) {
        errors.push(`åˆ†å—${i + 1}å¤„ç†å¼‚å¸¸: ${error.message}`)
      }
    }

    const uniqueAPIs = this.deduplicateAPIs(totalAPIs)
    const averageConfidence = successCount > 0 ? totalConfidence / successCount : 0

    return {
      apis: uniqueAPIs,
      success: uniqueAPIs.length > 0,
      errors: errors.length > 0 ? errors : (uniqueAPIs.length === 0 ? ['æ‰€æœ‰åˆ†å—éƒ½æœªèƒ½è§£æåˆ°APIæ¥å£'] : []),
      confidence: averageConfidence
    }
  }

  // è§£ææ•°æ®åº“æ–‡æ¡£
  async parseDatabaseDocument(content: string, projectId: string): Promise<ParsedDatabaseDocument> {
    try {
      const prompt = this.getDatabaseParsingPrompt()
      let result: any

      if (this.config.provider === 'ollama') {
        result = await this.callOllama(prompt, content)
      } else {
        result = await this.callOnlineAPI(prompt, content)
      }

      // è½¬æ¢ä¸ºæ ‡å‡†æ•°æ®è¡¨æ ¼å¼
      const tables: DatabaseTable[] = result.tables?.map((table: any, index: number) => ({
        id: `ai-parsed-table-${Date.now()}-${index}`,
        projectId,
        name: table.name || `table_${index}`,
        displayName: table.displayName || table.name,
        comment: table.comment || '',
        engine: table.engine || 'InnoDB',
        charset: table.charset || 'utf8mb4',
        collation: table.collation || 'utf8mb4_unicode_ci',
        status: 'ACTIVE' as any,
        createdAt: new Date().toISOString(),
        updatedAt: new Date().toISOString(),
        fields: table.fields?.map((field: any, fieldIndex: number) => ({
          id: `field-${Date.now()}-${fieldIndex}`,
          tableId: `ai-parsed-table-${Date.now()}-${index}`,
          name: field.name,
          type: field.type,
          length: field.length,
          nullable: field.nullable !== false,
          isPrimaryKey: field.isPrimaryKey || false,
          isAutoIncrement: field.isAutoIncrement || false,
          comment: field.comment || '',
          sortOrder: field.sortOrder || fieldIndex + 1,
          createdAt: new Date().toISOString(),
          updatedAt: new Date().toISOString()
        })) || []
      })) || []

      return {
        tables,
        success: tables.length > 0,
        errors: tables.length === 0 ? ['æœªèƒ½è§£æåˆ°ä»»ä½•æ•°æ®è¡¨'] : [],
        confidence: result.confidence || 0.8
      }
    } catch (error: any) {
      return {
        tables: [],
        success: false,
        errors: [error.message || 'è§£æå¤±è´¥'],
        confidence: 0
      }
    }
  }

  // æ ‡å‡†åŒ–HTTPæ–¹æ³•
  private normalizeHTTPMethod(method: string): HTTPMethod {
    const normalizedMethod = method?.toUpperCase()
    switch (normalizedMethod) {
      case 'GET': return HTTPMethod.GET
      case 'POST': return HTTPMethod.POST
      case 'PUT': return HTTPMethod.PUT
      case 'PATCH': return HTTPMethod.PATCH
      case 'DELETE': return HTTPMethod.DELETE
      case 'HEAD': return HTTPMethod.HEAD
      case 'OPTIONS': return HTTPMethod.OPTIONS
      default: return HTTPMethod.GET
    }
  }
}

// åˆ›å»ºé»˜è®¤çš„AIè§£ææœåŠ¡å®ä¾‹
export const createAIParsingService = (config: AIParsingConfig): AIParsingService => {
  return new AIParsingService(config)
}

// é¢„è®¾é…ç½®
export const AI_PARSING_PRESETS = {
  // æ¨¡æ‹Ÿæ¨¡å¼ï¼ˆç”¨äºè°ƒè¯•ï¼‰
  mock: {
    provider: 'mock' as const,
    model: 'mock-model',
    baseUrl: ''
  },
  // Ollamaæœ¬åœ°é…ç½®
  ollama_qwen: {
    provider: 'ollama' as const,
    model: 'qwen2.5-coder:7b',
    baseUrl: 'http://localhost:11434'
  },
  ollama_qwen_small: {
    provider: 'ollama' as const,
    model: 'qwen2.5-coder:1.5b',
    baseUrl: 'http://localhost:11434'
  },
  // DeepSeekåœ¨çº¿é…ç½®
  deepseek: {
    provider: 'deepseek' as const,
    model: 'deepseek-coder',
    baseUrl: 'https://api.deepseek.com',
    apiKey: import.meta.env.VITE_DEEPSEEK_API_KEY
  },
  // OpenAIé…ç½®
  openai: {
    provider: 'openai' as const,
    model: 'gpt-3.5-turbo',
    baseUrl: 'https://api.openai.com',
    apiKey: import.meta.env.VITE_OPENAI_API_KEY
  }
}

export default AIParsingService