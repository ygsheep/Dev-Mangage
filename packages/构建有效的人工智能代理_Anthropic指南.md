# 构建有效的人工智能代理 - Anthropic 指南

> **译者注**: 本文翻译自 Anthropic 官方发布的《Building Effective AI Agents》，为初学者添加了详细注解。
>
> **原文链接**: https://www.anthropic.com/research/building-effective-agents
>
> **适合人群**: AI 开发初学者、对 AI 代理感兴趣的开发者

## 📖 前言

在过去的一年中，我们与数十个跨行业构建大型语言模型（LLM）代理的团队合作。始终如一的是，最成功的实现并不是使用复杂的框架或专门的库，而是使用简单、可组合的模式进行构建。

> **初学者注解 🔰**:
>
> - **大型语言模型（LLM）**: 如 GPT、Claude 等能够理解和生成人类语言的 AI 模型
> - **代理（Agent）**: 能够自主决策并执行任务的 AI 系统
> - **可组合模式**: 可以像积木一样组合使用的设计模式

在这篇文章中，我们分享从与客户合作和自己构建代理中学到的经验，并为开发者提供构建有效代理的实用建议。

## 🤖 什么是代理？

"代理"可以有多种定义方式。一些客户将代理定义为完全自主的系统，在较长时间内独立运作，使用各种工具完成复杂任务。其他人使用这个术语来描述遵循预定义工作流程的更具规范性的实现。

在 Anthropic，我们将所有这些变体归类为**代理系统**，但在架构上区分工作流程和代理：

### 🔄 工作流程 vs 代理

- **工作流程（Workflows）**: 通过预定义代码路径编排 LLM 和工具的系统
- **代理（Agents）**: LLM 动态指导自己的过程和工具使用，保持对如何完成任务的控制的系统

> **初学者注解 🔰**:
>
> - **工作流程**: 像流水线一样，步骤固定，适合重复性任务
> - **代理**: 像助手一样，能够灵活决策，适合复杂多变的任务

下面，我们将详细探讨这两种类型的代理系统。在附录 1（"实践中的代理"）中，我们描述了客户发现这些系统特别有价值的两个领域。

## ⚖️ 何时使用（以及何时不使用）代理

在使用 LLM 构建应用程序时，我们建议找到尽可能简单的解决方案，只有在需要时才增加复杂性。这可能意味着根本不构建代理系统。

> **重要原则 ⚠️**: 简单优先！不要为了使用代理而使用代理。

代理系统通常会**用延迟和成本换取更好的任务性能**，您应该考虑这种权衡何时有意义。

### 🎯 选择指南

- **工作流程**: 适用于**明确定义的任务**，提供可预测性和一致性
- **代理**: 适用于需要**灵活性和模型驱动决策**的大规模应用
- **简单 LLM 调用**: 对于许多应用，优化单个 LLM 调用（结合检索和上下文示例）通常就足够了

> **初学者注解 🔰**:
>
> - **延迟**: 系统响应时间
> - **检索**: 从数据库或文档中查找相关信息
> - **上下文示例**: 提供给 AI 的示例，帮助它理解任务

## 🛠️ 何时以及如何使用框架

有许多框架使代理系统更容易实现，包括：

- [LangGraph](https://langchain-ai.github.io/langgraph/) (来自 LangChain)
- Amazon Bedrock 的 [AI Agent framework](https://aws.amazon.com/bedrock/agents/)
- [Rivet](https://rivet.ironcladapp.com/) (拖拽式 GUI LLM 工作流构建器)
- [Vellum](https://www.vellum.ai/) (另一个用于构建和测试复杂工作流的 GUI 工具)

### 📋 框架的优缺点

**优点**:

- 简化标准底层任务（调用 LLM、定义和解析工具、链式调用）
- 快速上手

**缺点**:

- 创建额外的抽象层，可能掩盖底层提示和响应
- 使调试变得困难
- 可能诱导添加不必要的复杂性

> **最佳实践 💡**:
>
> 1. 开发者应首先直接使用 LLM API（许多模式可以用几行代码实现）
> 2. 如果使用框架，确保理解底层代码
> 3. 对底层工作原理的错误假设是客户错误的常见来源

查看我们的 [cookbook](https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents) 了解一些示例实现。

## 🧱 构建块、工作流程和代理

在本节中，我们将探讨生产环境中代理系统的常见模式。我们将从基础构建块——增强型 LLM 开始，逐步增加复杂性，从简单的组合工作流程到自主代理。

### 🔧 构建块：增强型 LLM

代理系统的基本构建块是通过**检索、工具和内存**等增强功能增强的 LLM。我们当前的模型可以主动使用这些功能——生成自己的搜索查询、选择适当的工具并确定要保留的信息。

> **初学者注解 🔰**:
>
> - **检索**: 从外部数据源获取信息的能力
> - **工具**: AI 可以调用的外部功能（如计算器、API 等）
> - **内存**: 记住之前对话内容的能力

![增强型 LLM 架构图](https://www-cdn.anthropic.com/images/4zrzovbb/website/d3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png)

我们建议关注实现的两个关键方面：

1. **为您的特定用例量身定制这些功能**
2. **确保它们为您的 LLM 提供易于使用、文档完善的接口**

一种实现方法是通过我们最近发布的 [模型上下文协议（Model Context Protocol）](https://www.anthropic.com/news/model-context-protocol)，它允许开发者通过简单的[客户端实现](https://modelcontextprotocol.io/tutorials/building-a-client#building-mcp-clients)与不断增长的第三方工具生态系统集成。

在本文的其余部分，我们假设每个 LLM 调用都可以访问这些增强功能。

{
`content`: `

## 🔗 工作流程模式

### 1. 提示链（Prompt Chaining）

提示链将任务分解为一系列步骤，其中每个 LLM 调用处理前一个调用的输出。您可以在任何中间步骤添加程序化检查（见下图中的\"gate\"）以确保过程仍在正轨上。

![提示链架构图](https://www-cdn.anthropic.com/images/4zrzovbb/website/7418719e3dab222dccb379b8879e1dc08ad34c78-2401x1000.png)

**何时使用此工作流程**: 当任务可以轻松、清晰地分解为固定子任务时。主要目标是通过使每个 LLM 调用成为更容易的任务来权衡延迟以获得更高的准确性。

> **初学者注解 🔰**:
>
> - **提示链**: 像接力赛一样，一个步骤的输出成为下一个步骤的输入
> - **程序化检查**: 自动验证中间结果是否符合要求

**提示链有用的示例**:

- 生成营销文案，然后将其翻译成不同语言
- 编写文档大纲，检查大纲是否符合特定标准，然后基于大纲编写文档

### 2. 路由（Routing）

路由对输入进行分类并将其导向专门的后续任务。此工作流程允许关注点分离，构建更专门的提示。没有此工作流程，针对一种输入类型的优化可能会损害其他输入的性能。

![路由架构图](https://www-cdn.anthropic.com/images/4zrzovbb/website/5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png)

**何时使用此工作流程**: 路由适用于复杂任务，其中有不同的类别最好单独处理，并且分类可以准确处理，无论是通过 LLM 还是更传统的分类模型/算法。

> **初学者注解 🔰**:
>
> - **路由**: 像邮局分拣邮件一样，根据类型将请求发送到不同的处理器
> - **关注点分离**: 让每个组件专注于处理特定类型的任务

**路由有用的示例**:

- 将不同类型的客户服务查询（一般问题、退款请求、技术支持）导向不同的下游流程、提示和工具
- 将简单/常见问题路由到较小的模型（如 Claude 3.5 Haiku），将困难/不寻常的问题路由到更强大的模型（如 Claude 3.5 Sonnet）以优化成本和速度

### 3. 并行化（Parallelization）

LLM 有时可以同时处理任务并以编程方式聚合其输出。此工作流程——并行化，体现在两个关键变体中：

- **分段**: 将任务分解为并行运行的独立子任务
- **投票**: 多次运行相同任务以获得多样化输出

![并行化架构图](https://www-cdn.anthropic.com/images/4zrzovbb/website/406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png)

**何时使用此工作流程**: 当分割的子任务可以并行化以提高速度时，或当需要多个视角或尝试以获得更高置信度结果时，并行化是有效的。

> **初学者注解 🔰**:
>
> - **并行化**: 像多个人同时工作一样，可以大大提高效率
> - **分段**: 将大任务切分成小块分别处理
> - **投票**: 多个 AI 处理同一任务，通过\"投票\"决定最佳结果

**并行化有用的示例**:

**分段**:

- 实施保护机制，其中一个模型实例处理用户查询，而另一个筛选不当内容或请求。这往往比让同一个 LLM 调用同时处理保护机制和核心响应表现更好
- 自动化评估 LLM 性能，其中每个 LLM 调用评估模型在给定提示上性能的不同方面

**投票**:

- 审查代码漏洞，其中几个不同的提示审查并在发现问题时标记代码
- 评估给定内容是否不当，多个提示评估不同方面或需要不同投票阈值来平衡误报和漏报

### 4. 编排者-工作者（Orchestrator-Workers）

在编排者-工作者工作流程中，中央 LLM 动态分解任务，将其委托给工作者 LLM，并综合其结果。

![编排者-工作者架构图](https://www-cdn.anthropic.com/images/4zrzovbb/website/8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png)

**何时使用此工作流程**: 此工作流程非常适合无法预测所需子任务的复杂任务（例如，在编码中，需要更改的文件数量和每个文件中更改的性质可能取决于任务）。

> **初学者注解 🔰**:
>
> - **编排者**: 像项目经理一样，负责分配任务和协调工作
> - **工作者**: 像专业技术人员一样，专注于执行具体任务
> - **动态分解**: 根据具体情况灵活决定如何分工

虽然在拓扑上相似，但与并行化的关键区别在于其灵活性——子任务不是预定义的，而是由编排者根据特定输入确定的。

**编排者-工作者有用的示例**:

- 每次对多个文件进行复杂更改的编码产品
- 涉及从多个来源收集和分析信息以获取可能相关信息的搜索任务

### 5. 评估者-优化者（Evaluator-Optimizer）

在评估者-优化者工作流程中，一个 LLM 调用生成响应，而另一个在循环中提供评估和反馈。

![评估者-优化者架构图](https://www-cdn.anthropic.com/images/4zrzovbb/website/14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png)

**何时使用此工作流程**: 当我们有明确的评估标准，并且迭代改进提供可衡量价值时，此工作流程特别有效。

> **初学者注解 🔰**:
>
> - **评估者-优化者**: 像作家写作和编辑的过程，一个负责创作，一个负责改进
> - **迭代改进**: 反复修改直到达到满意的质量

良好拟合的两个迹象是：

1. **当人类表达反馈时，LLM 响应可以得到明显改善**
2. **LLM 可以提供这样的反馈**

这类似于人类作家在制作精美文档时可能经历的迭代写作过程。

**评估者-优化者有用的示例**:

- 文学翻译，其中有翻译者 LLM 最初可能无法捕获的细微差别，但评估者 LLM 可以提供有用的批评
- 需要多轮搜索和分析以收集全面信息的复杂搜索任务，其中评估者决定是否需要进一步搜索

## 🤖 代理（Agents）

随着 LLM 在关键能力方面的成熟——理解复杂输入、参与推理和规划、可靠地使用工具以及从错误中恢复——代理正在生产中出现。

### 🔄 代理工作流程

代理从人类用户的命令或交互式讨论开始工作。一旦任务明确，代理独立规划和操作，可能返回给人类以获取更多信息或判断。

> **初学者注解 🔰**:
>
> - **自主性**: 代理能够独立决策和行动
> - **规划**: 制定完成任务的步骤计划
> - **恢复**: 当出错时能够自我纠正

在执行过程中，代理在每一步都从环境中获得\"基本事实\"（如工具调用结果或代码执行）以评估其进度至关重要。代理然后可以在检查点或遇到阻塞时暂停以获取人类反馈。

任务通常在完成时终止，但包含停止条件（如最大迭代次数）以保持控制也很常见。

![代理架构图](https://www-cdn.anthropic.com/images/4zrzovbb/website/58d9f10c985c4eb5d53798dea315f7bb5ab6249e-2401x1000.png)

### 🎯 代理的特点

代理可以处理复杂的任务，但其实现通常很简单。它们通常只是在循环中基于环境反馈使用工具的 LLM。因此，**清晰周到地设计工具集及其文档至关重要**。

> **重要提醒 ⚠️**: 代理的自主特性意味着更高的成本和复合错误的潜力。我们建议在沙盒环境中进行大量测试，以及适当的保护措施。

**何时使用代理**: 代理可用于开放式问题，其中很难或不可能预测所需的步骤数，并且您无法硬编码固定路径。LLM 将可能运行许多轮次，您必须对其决策具有一定程度的信任。代理的自主性使其成为在可信环境中扩展任务的理想选择。

### 📝 代理有用的示例

以下示例来自我们自己的实现：

- **编码代理**，用于解决 [SWE-bench 任务](https://www.anthropic.com/research/swe-bench-sonnet)，涉及基于任务描述对许多文件进行编辑
- 我们的 [\"计算机使用\"参考实现](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)，其中 Claude 使用计算机完成任务

![计算机使用示例](https://www-cdn.anthropic.com/images/4zrzovbb/website/4b9a1f4eb63d5962a6e1746ac26bbc857cf3474f-2400x1666.png)

> **初学者注解 🔰**:
>
> - **SWE-bench**: 软件工程基准测试，用于评估 AI 解决编程问题的能力
> - **计算机使用**: AI 直接控制鼠标键盘等来操作计算机界面

## 🧩 组合和定制这些模式

这些构建块不是规定性的。它们是开发者可以塑造和组合以适应不同用例的常见模式。成功的关键，就像任何 LLM 功能一样，是**衡量性能并迭代实现**。

> **核心原则 💡**: 只有在复杂性明显改善结果时才考虑添加复杂性。

## 📋 总结

LLM 领域的成功不在于构建最复杂的系统，而在于**构建适合您需求的正确系统**。

### 🎯 三步法则

1. **从简单的提示开始**
2. **通过全面评估优化它们**
3. **只有在简单解决方案不足时才添加多步代理系统**

### 🔑 实施代理的三个核心原则

当实施代理时，我们努力遵循三个核心原则：

1. **在代理设计中保持简单性**
2. **通过明确显示代理的规划步骤来优先考虑透明度**
3. **通过彻底的工具文档和测试仔细制作您的代理-计算机接口（ACI）**

> **初学者注解 🔰**:
>
> - **ACI (Agent-Computer Interface)**: 代理与计算机系统交互的接口，类似于人机交互界面
> - **透明度**: 让用户能够理解代理在做什么和为什么这样做

### 🛠️ 关于框架的建议

框架可以帮助您快速入门，但在迁移到生产环境时，不要犹豫减少抽象层并使用基本组件构建。

通过遵循这些原则，您可以创建不仅强大而且**可靠、可维护且受用户信任**的代理。

---

## 📚 附录 1：实践中的代理

我们与客户的合作揭示了 AI 代理的两个特别有前景的应用，这些应用展示了上述讨论模式的实用价值。这两个应用都说明了代理在需要对话和行动、具有明确成功标准、启用反馈循环并整合有意义的人类监督的任务中增加最多价值。

### A. 客户支持

客户支持通过工具集成将熟悉的聊天机器人界面与增强功能相结合。这对于更开放式的代理来说是自然的选择，因为：

- 支持交互自然遵循对话流程，同时需要访问外部信息和行动
- 工具可以集成以提取客户数据、订单历史和知识库文章
- 发放退款或更新工单等行动可以通过编程处理
- 成功可以通过用户定义的解决方案清楚地衡量

> **初学者注解 🔰**:
>
> - **客户支持代理**: 能够自动处理客户咨询、查询信息、执行操作的 AI 系统
> - **知识库**: 包含常见问题解答和解决方案的数据库

几家公司通过基于使用的定价模式展示了这种方法的可行性，该模式仅对成功解决方案收费，显示了对其代理有效性的信心。

### B. 编码代理

软件开发领域显示了 LLM 功能的巨大潜力，能力从代码完成发展到自主问题解决。代理特别有效，因为：

- 代码解决方案可通过自动测试验证
- 代理可以使用测试结果作为反馈来迭代解决方案
- 问题空间定义明确且结构化
- 输出质量可以客观衡量

> **初学者注解 🔰**:
>
> - **自动测试**: 程序自动检查代码是否正确工作
> - **迭代**: 反复改进直到达到要求

在我们自己的实现中，代理现在可以仅基于拉取请求描述解决 [SWE-bench Verified](https://www.anthropic.com/research/swe-bench-sonnet) 基准测试中的真实 GitHub 问题。然而，虽然自动测试有助于验证功能，但人类审查对于确保解决方案与更广泛的系统要求一致仍然至关重要。

---

## 🔧 附录 2：提示工程您的工具

无论您正在构建哪种代理系统，工具都可能是您代理的重要组成部分。[工具](https://www.anthropic.com/news/tool-use-ga) 通过在我们的 API 中指定其确切结构和定义，使 Claude 能够与外部服务和 API 交互。

> **初学者注解 🔰**:
>
> - **工具**: AI 可以调用的外部功能，如搜索引擎、计算器、API 等
> - **API**: 应用程序编程接口，允许不同软件之间交互

### 🎨 工具设计原则

通常有几种方式来指定相同的操作。例如，您可以通过编写差异或重写整个文件来指定文件编辑。对于结构化输出，您可以在 markdown 或 JSON 内返回代码。

在软件工程中，这些差异是表面的，可以无损地从一种转换为另一种。然而，**某些格式对 LLM 来说比其他格式更难编写**。

> **格式选择的考虑因素 📝**:
>
> - **编写差异**: 需要在编写新代码之前知道块头中有多少行正在更改
> - **JSON 中的代码**: 与 markdown 相比需要额外的换行符和引号转义

### 💡 工具格式决策建议

1. **给模型足够的令牌在写入困境前\"思考\"**
2. **保持格式接近模型在互联网文本中自然看到的内容**
3. **确保没有格式\"开销\"**，如必须保持数千行代码的准确计数，或对其编写的任何代码进行字符串转义

> **初学者注解 🔰**:
>
> - **令牌**: AI 处理文本的基本单位
> - **字符串转义**: 在特殊字符前添加反斜杠等，以避免格式冲突

### 🎯 代理-计算机接口（ACI）设计

一个经验法则是思考人机界面（HCI）投入的努力程度，并计划在创建良好的代理-计算机界面（ACI）上投入同样多的努力。

#### 🛠️ 优化 ACI 的建议

1. **换位思考**: 基于描述和参数，使用这个工具是否显而易见，还是您需要仔细思考？如果是这样，那么对模型来说可能也是如此

2. **优化参数名称和描述**: 将其视为为团队中的初级开发者编写出色的文档字符串。当使用许多类似工具时，这尤其重要

3. **测试模型如何使用您的工具**: 在我们的 [workbench](https://console.anthropic.com/workbench) 中运行许多示例输入，查看模型犯了什么错误，并迭代

4. **防错设计您的工具**: 更改参数，使犯错误变得更困难

> **初学者注解 🔰**:
>
> - **文档字符串**: 描述函数用途和使用方法的注释
> - **防错设计**: 让系统难以被错误使用的设计理念
> - **Workbench**: Anthropic 提供的测试工具界面

### 📖 实际案例：SWE-bench 代理

在为 [SWE-bench](https://www.anthropic.com/research/swe-bench-sonnet) 构建代理时，我们实际上花费了更多时间优化工具而不是整体提示。

**案例分析**: 我们发现模型在代理移出根目录后会在使用相对文件路径的工具上犯错误。为了解决这个问题，我们更改了工具以始终需要绝对文件路径——我们发现模型完美无缺地使用了这种方法。

> **关键洞察 💡**: 工具设计的微小改进可以
